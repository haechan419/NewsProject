import os
import time
import json
import re
import mysql.connector
from moviepy.config import change_settings 
from moviepy.editor import *
from moviepy.audio.AudioClip import AudioClip 
from moviepy.audio.fx.all import audio_fadein, audio_fadeout
<<<<<<< HEAD
from dotenv import load_dotenv
import media_tools 
import openai

# [1. Í≤ΩÎ°ú Î∞è ÌôòÍ≤Ω ÏÑ§Ï†ï]
# .env ÌååÏùºÏóêÏÑú ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú
load_dotenv()

# Ïù¥ÎØ∏ÏßÄÎß§ÏßÅ Í≤ΩÎ°ú (ÏÇ¨Ïö©ÏûêÎãò ÌôòÍ≤Ω Ïú†ÏßÄ)
IMAGEMAGICK_BINARY = r"D:\ImageMagick-7.1.2-Q16-HDRI\magick.exe"
change_settings({"IMAGEMAGICK_BINARY": IMAGEMAGICK_BINARY})

#OpenAI API Key ÏÑ§Ï†ï (.env ÌååÏùºÏóêÏÑú Î°úÎìú)
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    print("[Í≤ΩÍ≥†] OPENAI_API_KEYÍ∞Ä .env ÌååÏùºÏóê ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")


# ÌåÄ ÌîÑÎ°úÏ†ùÌä∏ DB ÏÑ§Ï†ï (newsdbÎ°ú ÌÜµÌï©)
DB_CONFIG = {
    'host': 'localhost', 
    'user': 'newsuser', 
    'password': 'newsuser', 
    'database': 'newsdb' # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î™Ö ÏàòÏ†ï ÏôÑÎ£å
}

# ÏòÅÏÉÅ Í≤∞Í≥ºÎ¨ºÏù¥ Ï†ÄÏû•Îê† Î∞±ÏóîÎìú Í≤ΩÎ°ú (Spring Boot upload Ìè¥Îçî)
# Íµ¨Ï°∞: NEWSPROJECT-MASTER/fullStc/upload/videos
OUTPUT_DIR = r"D:\NewsProject-master\NewsProject-master\fullStc\upload\videos"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ------------------------------------------------------------------------------
# [2. AI Director: Ïä§ÌÜ†Î¶¨Î≥¥Îìú ÏÉùÏÑ±]
# ------------------------------------------------------------------------------
def get_storyboard_from_ai(news_text):
    print("[AI Director] Îâ¥Ïä§ ÏöîÏïΩÎ≥∏ Í∏∞Î∞ò ÏòÅÏÉÅ Íµ¨ÏÑ± Ï§ë...")
    system_prompt = """
    ÎÑàÎäî Ï†ÑÎ¨∏ Îâ¥Ïä§ ÏòÅÏÉÅ Ìé∏ÏßëÏûêÏïº. Îã§Ïùå Îã®Í≥ÑÎ•º Í±∞Ï≥ê 30Ï¥à Ïù¥ÎÇ¥Ïùò ÏàèÌèº Ïä§ÌÅ¨Î¶ΩÌä∏Î•º ÏßúÏ§ò.

    1. [Ï†ÑÏ≤¥ Îß•ÎùΩ ÌååÏïÖ]: ÏûÖÎ†•Îêú Í∏∞ÏÇ¨ Ï†ÑÏ≤¥Ïùò ÌïµÏã¨ Ï£ºÏ†úÎ•º Î®ºÏ†Ä ÌååÏïÖÌï¥.
    2. [Ïû•Î©¥ Íµ¨ÏÑ±]: Í∏∞ÏÇ¨Î•º ÏÑúÎ°†-Î≥∏Î°†-Í≤∞Î°† 3Ïû•Î©¥ÏúºÎ°ú ÏöîÏïΩÌï¥.
    3. [ÌÇ§ÏõåÎìú ÏÑ†Ïñ∏]: Í∞Å Î¨∏Ïû•Ïùò ÌÇ§ÏõåÎìúÎäî 'Ï†ÑÏ≤¥ Ï£ºÏ†ú'ÏôÄ 'Ìï¥Îãπ Î¨∏Ïû•'Ïùò Ïó∞Í≤∞Í≥†Î¶¨Î•º Í≥†Î†§Ìï¥ ÏûëÏÑ±Ìï¥.
       - Î∞òÎìúÏãú **Íµ¨Ï≤¥Ï†ÅÏù∏ ÏãúÍ∞ÅÏ†Å Î¨òÏÇ¨Í∞Ä Îã¥Í∏¥ ÏòÅÏñ¥(English)**Î°ú ÏûëÏÑ±Ìï† Í≤É.
       - Ïòà: Ï†ÑÏ≤¥ Ï£ºÏ†úÍ∞Ä 'ÏÇºÏÑ± Î∞òÎèÑÏ≤¥'ÎùºÎ©¥, 'ÌòÅÏã†'Ïù¥ÎùºÎäî Î¨∏Ïû•Ïùò ÌÇ§ÏõåÎìúÎäî 'Innovation'Ïù¥ ÏïÑÎãàÎùº 
         'Advanced microchip glowing circuit board'ÏôÄ Í∞ôÏù¥ Ìï¥Îãπ Îß•ÎùΩÏùò ÏÇ¨Î¨ºÎ°ú ÏßÄÏ†ïÌï¥.
    4. [ÏãúÍ∞Ñ Ï†úÌïú]: Ï†ÑÏ≤¥ Î∂ÑÎüâÏùÄ 25~30Ï¥à ÏÇ¨Ïù¥, Ï¥ù Í∏ÄÏûê ÏàòÎäî 150Ïûê Ïù¥ÎÇ¥Î°ú Ï†úÌïúÌï¥.

    Ï∂úÎ†• ÌòïÏãù: Ïò§ÏßÅ JSON [ {"text": "...", "keyword": "...", "type": "video"} ]
    """
=======
import media_tools 
import openai

# [1. ÏÑ§Ï†ï]
IMAGEMAGICK_BINARY = r"D:\ImageMagick-7.1.2-Q16-HDRI\magick.exe"
change_settings({"IMAGEMAGICK_BINARY": IMAGEMAGICK_BINARY})

DB_CONFIG = {
    'host': 'localhost', 
    'user': 'root', 
    'password': '1234', 
    'database': 'newsdb'
}

OUTPUT_DIR = r"D:\1teamnews\fullStc\upload\videos"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# [2. AI Ïä§ÌÜ†Î¶¨Î≥¥Îìú ÏÉùÏÑ±]
def get_storyboard_from_ai(news_text):
    print("ü§ñ [AI Director] Îß•ÎùΩ Ïù∏ÏßÄÌòï Ïä§ÌÅ¨Î¶ΩÌä∏ Íµ¨ÏÑ± Ï§ë...")
    system_prompt = "ÎÑàÎäî '30Ï¥à Îâ¥Ïä§' Ìé∏ÏßëÏûêÏïº. ÌòïÏãù: JSON [ {'text': '...', 'keyword': '...', 'type': 'video'} ] Îßå Ï∂úÎ†•Ìï¥."
>>>>>>> a946f6f6b18974710cc396ee87547a607e4cf163
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": news_text}]
        )
        content = response.choices[0].message.content.strip()
<<<<<<< HEAD
        content = content.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\[.*\]', content, re.DOTALL)
        return json.loads(match.group()) if match else None
    except Exception as e:
        print(f"[AI Î∂ÑÏÑù Ïò§Î•ò] {e}")
        return None

# ------------------------------------------------------------------------------
# [3. Ïû•Î©¥ Ï†úÏûë Î°úÏßÅ (ÏÇ¨Ïö©Ïûê ÏõêÎ≥∏ Ïú†ÏßÄ)]
# ------------------------------------------------------------------------------
=======
        match = re.search(r'\[.*\]', content.replace("```json", "").replace("```", ""), re.DOTALL)
        return json.loads(match.group()) if match else None
    except Exception as e:
        print(f"‚ö†Ô∏è AI Î∂ÑÏÑù Ïò§Î•ò (APIÌÇ§/ÏûîÏï° ÌôïÏù∏ ÌïÑÏöî): {e}")
        return None

# [3. Î≥¥Ï°∞ Ìï®ÏàòÎì§]
>>>>>>> a946f6f6b18974710cc396ee87547a607e4cf163
def split_text_natural(text, min_len=8, max_len=18):
    words = text.split(' ')
    chunks, current_chunk, current_len = [], [], 0
    markers = ["ÏùÄ", "Îäî", "Ïù¥", "Í∞Ä", "ÏùÑ", "Î•º", "Ïóê", "ÏÑú", "Î°ú", "Í≥†", "Î©∞", "Ïöî", "Ï£†", "Îã§"]
    for word in words:
        current_chunk.append(word); current_len += len(word) + 1
        if current_len >= max_len or (current_len >= min_len and any(word.endswith(m) for m in markers)):
            chunks.append(' '.join(current_chunk)); current_chunk, current_len = [], 0
    if current_chunk: chunks.append(' '.join(current_chunk))
    return chunks

<<<<<<< HEAD
def get_compatible_silence(duration, reference_clip):
    fps, nchannels = reference_clip.fps, reference_clip.nchannels
    make_frame = lambda t: [0]*nchannels if nchannels > 1 else 0
    return AudioClip(make_frame, duration=duration, fps=fps)

def make_scene_clip(text, keyword, media_type, index, video_mode="16:9"):
    is_portrait = (video_mode == "9:16")
    target_w, target_h = (720, 1280) if is_portrait else (1280, 720)
    font_scale = 0.065 if is_portrait else 0.045
    subtitle_max_len = 16 if is_portrait else 25
    
    audio_path = os.path.abspath(f"temp_audio_{index}.mp3")
    media_path_base = os.path.abspath(f"temp_media_{index}")
    temp_files = [audio_path]
    
    media_tools.create_tts(text, audio_path)
    time.sleep(1.0)
    tts_clip = AudioFileClip(audio_path)
    
    # Ïò§ÎîîÏò§ Ìå®Îî©
    p_start = get_compatible_silence(0.1, tts_clip)
    p_end = get_compatible_silence(0.5, tts_clip)
    tts_clip = tts_clip.fx(audio_fadein, 0.05).fx(audio_fadeout, 0.1)
    final_audio = concatenate_audioclips([p_start, tts_clip, p_end])
    duration = final_audio.duration

    # ÎπÑÏ£ºÏñº ÏÜåÏä§ ÌôïÎ≥¥
    visual_clip = None
    media_path_img = media_path_base + ".jpg"
    media_path_vid = media_path_base + ".mp4"

    if media_type == 'image':
        if media_tools.generate_free_image(keyword, media_path_img, is_portrait):
            visual_clip = ImageClip(media_path_img).set_duration(duration)
            temp_files.append(media_path_img)

    if visual_clip is None: # ÎπÑÎîîÏò§ ÏãúÎèÑ
        if media_tools.download_pexels_video(keyword, media_path_vid, is_portrait):
            visual_clip = VideoFileClip(media_path_vid)
            temp_files.append(media_path_vid)
        else:
            visual_clip = ColorClip(size=(target_w, target_h), color=(30, 30, 30)).set_duration(duration)

    visual_clip = visual_clip.resize(newsize=(target_w, target_h))
    if hasattr(visual_clip, 'duration'):
        visual_clip = vfx.loop(visual_clip, duration=duration) if visual_clip.duration < duration else visual_clip.subclip(0, duration)
    
    visual_clip = visual_clip.set_audio(final_audio)

    # ÏûêÎßâ ÏÉùÏÑ±
    text_chunks = split_text_natural(text, min_len=8, max_len=subtitle_max_len)
    active_duration = tts_clip.duration
    start_time = 0.1
    sub_clips = []
    
    for chunk in text_chunks:
        c_duration = (len(chunk)/len(text)) * active_duration
        txt = TextClip(chunk, fontsize=int(target_w*font_scale), color='white', font="C:/Windows/Fonts/malgun.ttf", 
                       method='caption', align='center', size=(int(target_w*0.9), None))
        bg = ColorClip(size=(target_w, txt.h + 50), color=(0,0,0)).set_opacity(0.6)
        block = CompositeVideoClip([bg, txt.set_position('center')], size=bg.size).set_position(('center', 'bottom')).set_start(start_time).set_duration(c_duration)
        sub_clips.append(block)
        start_time += c_duration

    return CompositeVideoClip([visual_clip] + sub_clips), temp_files

# ------------------------------------------------------------------------------
# [4. Î©îÏù∏ Î£®ÌîÑ: DB Ïó∞Îèô Î∞è ÏûëÏóÖ Ï≤òÎ¶¨]
# ------------------------------------------------------------------------------
def run_engine():
    print("[Engine] Îâ¥Ïä§ ÏòÅÏÉÅ Ï†úÏûë ÏùºÍæºÏù¥ Ï∂úÍ∑ºÌñàÏäµÎãàÎã§! (newsdb Í∞êÏãú Ï§ë)")
    while True:
        conn = None
=======
def make_scene_clip(text, keyword, media_type, index, video_mode="16:9"):
    is_portrait = (video_mode == "9:16")
    target_w, target_h = (720, 1280) if is_portrait else (1280, 720)
    audio_path = os.path.abspath(f"temp_audio_{index}.mp3")
    media_path_img = os.path.abspath(f"temp_media_{index}.jpg")
    media_path_vid = os.path.abspath(f"temp_media_{index}.mp4")
    temp_files = [audio_path]

    if not media_tools.create_tts(text, audio_path): return None, []
    
    tts_clip = AudioFileClip(audio_path)
    duration = tts_clip.duration + 0.6
    
    visual_clip = None
    if media_type == 'image' and media_tools.generate_free_image(keyword, media_path_img, is_portrait):
        visual_clip = ImageClip(media_path_img).set_duration(duration)
        temp_files.append(media_path_img)
    elif media_tools.download_pexels_video(keyword, media_path_vid, is_portrait):
        visual_clip = VideoFileClip(media_path_vid)
        temp_files.append(media_path_vid)
    
    if visual_clip is None:
        visual_clip = ColorClip(size=(target_w, target_h), color=(30, 30, 30)).set_duration(duration)

    visual_clip = visual_clip.resize(newsize=(target_w, target_h))
    if hasattr(visual_clip, 'duration') and visual_clip.duration < duration:
        visual_clip = vfx.loop(visual_clip, duration=duration)
    else:
        visual_clip = visual_clip.subclip(0, duration)

    return visual_clip.set_audio(tts_clip), temp_files

# [4. Î©îÏù∏ ÏóîÏßÑ Î£®ÌîÑ]
def run_engine():
    print("üöÄ [Engine] Îâ¥Ïä§ ÏòÅÏÉÅ Ï†úÏûë ÏóîÏßÑ Í∞ÄÎèô ÏãúÏûë!")
    while True:
        # ‚òÖ Ï§ëÏöî: Î™®Îì† Ï£ºÏöî Î≥ÄÏàòÎ•º Î£®ÌîÑ ÏãúÏûë Ïãú NoneÏúºÎ°ú Ï¥àÍ∏∞Ìôî (NameError Î∞©ÏßÄ)
        conn = None
        task = None
        final_video = None
        final_clips = []
        all_temps = []

>>>>>>> a946f6f6b18974710cc396ee87547a607e4cf163
        try:
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor(dictionary=True)
            
<<<<<<< HEAD
            # PENDING ÏÉÅÌÉúÏù∏ ÏûëÏóÖ 1Í∞ú Í∞ÄÏ†∏Ïò§Í∏∞
            cursor.execute("""
    SELECT * FROM tbl_video_task 
    WHERE status = 'PENDING' 
    AND regdate > NOW() - INTERVAL 15 MINUTE
    ORDER BY vno ASC LIMIT 1
""")
=======
            cursor.execute("""
                SELECT * FROM tbl_video_task 
                WHERE status = 'PENDING' 
                ORDER BY vno ASC LIMIT 1
            """)
>>>>>>> a946f6f6b18974710cc396ee87547a607e4cf163
            task = cursor.fetchone()

            if task:
                vno = task['vno']
<<<<<<< HEAD
                print(f"[Job {vno}] Ï†úÏûëÏùÑ ÏãúÏûëÌï©ÎãàÎã§. (Ïú†Ìòï: {task['task_type']})")
                
                cursor.execute("UPDATE tbl_video_task SET status = 'PROCESSING' WHERE vno = %s", (vno,))
                conn.commit()

                # Ïä§ÌÜ†Î¶¨Î≥¥Îìú ÏÉùÏÑ±
                story_board = get_storyboard_from_ai(task['raw_text'])
                if not story_board:
                    story_board = [{"text": "Í∏∞ÏÇ¨Î•º Î∂ÑÏÑùÌïòÎäî Ï§ëÏûÖÎãàÎã§.", "keyword": "digital news", "type": "video"}]

                final_clips, all_temps = [], []
                for i, scene in enumerate(story_board):
                    # video_mode Ïª¨ÎüºÏù¥ ÏóÜÏùÑ Í≤ΩÏö∞Î•º ÎåÄÎπÑÌï¥ Í∏∞Î≥∏Í∞í "16:9" ÏÇ¨Ïö©
                    v_mode = task.get('video_mode', '16:9')
                    clip, files = make_scene_clip(scene.get('text', ''), scene.get('keyword', 'news'), scene.get('type', 'video'), i, v_mode)
                    final_clips.append(clip)
                    all_temps.extend(files)

                # Í≤∞Í≥ºÎ¨º ÌååÏùºÎ™Ö Î∞è Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï
                file_name = f"result_vno_{vno}.mp4"
                save_path = os.path.join(OUTPUT_DIR, file_name)

                final_video = concatenate_videoclips(final_clips, method="compose")
                final_video.write_videofile(save_path, fps=24, codec='libx264', audio_codec='libmp3lame', threads=4)
                
                # ÏûêÏõê Ìï¥Ï†ú (WinError 32 Î∞©ÏßÄ)
                final_video.close()
                for c in final_clips: c.close()
                time.sleep(2)

                # DB ÏóÖÎç∞Ïù¥Ìä∏ (ÏôÑÎ£å ÏÉÅÌÉú Î∞è ÏòÅÏÉÅ URL Ï†ÄÏû•)
                cursor.execute("UPDATE tbl_video_task SET status = 'COMPLETED', video_url=%s WHERE vno = %s", (file_name, vno))
                conn.commit()
                print(f"[Job {vno}] Ï†úÏûë ÏôÑÎ£å! Ï†ÄÏû• ÏúÑÏπò: {save_path}")
                
                # ÏûÑÏãú ÌååÏùº ÏÇ≠Ï†ú
                for f in all_temps:
                    if f and os.path.exists(f):
                        try: os.remove(f)
                        except: pass
            
            cursor.close()
        except Exception as e:
            print(f"[Error] ÏóîÏßÑ ÏûëÎèô Ï§ë ÏóêÎü¨ Î∞úÏÉù: {e}")
        finally: 
            if conn: conn.close()
        
        time.sleep(10) # 10Ï¥àÎßàÎã§ DB ÌôïÏù∏
=======
                print(f"üé¨ [Job {vno}] Ï†úÏûëÏùÑ ÏãúÏûëÌï©ÎãàÎã§.")

                # AI Î∂ÑÏÑù ÏàòÌñâ
                story_board = get_storyboard_from_ai(task['raw_text'])
                
                # AI Î∂ÑÏÑù Ïã§Ìå® Ïãú (APIÌÇ§ Ïò§Î•ò Îì±)
                if not story_board:
                    print(f"‚ùå [Job {vno}] AI Î∂ÑÏÑù Ïã§Ìå®. ÏûëÏóÖÏùÑ Ï§ëÎã®Ìï©ÎãàÎã§.")
                    cursor.execute("UPDATE tbl_video_task SET status = 'FAILED' WHERE vno = %s", (vno,))
                    conn.commit()
                    continue

                v_mode = task.get('video_mode', '9:16')
                for i, scene in enumerate(story_board):
                    clip, files = make_scene_clip(scene['text'], scene['keyword'], scene['type'], i, v_mode)
                    if clip:
                        final_clips.append(clip)
                        all_temps.extend(files)

                if final_clips:
                    file_name = f"result_vno_{vno}.mp4"
                    save_path = os.path.join(OUTPUT_DIR, file_name)
                    
                    final_video = concatenate_videoclips(final_clips, method="compose")
                    final_video.write_videofile(save_path, fps=24, codec='libx264', audio_codec='libmp3lame', threads=4)
                    
                    cursor.execute("UPDATE tbl_video_task SET status = 'COMPLETED', video_url=%s WHERE vno = %s", (file_name, vno))
                    conn.commit()
                    print(f"‚úÖ [Job {vno}] Ï†úÏûë ÏôÑÎ£å!")

            cursor.close()
        except Exception as e:
            # task Î≥ÄÏàòÍ∞Ä Ï†ïÏùòÎêú Í≤ΩÏö∞ÏóêÎßå ÏûëÏóÖ Î≤àÌò∏ Ï∂úÎ†•
            vno_str = f"Job {task['vno']}" if task else "Unknown Job"
            print(f"‚ùå [Error] {vno_str} ÏóîÏßÑ ÏûëÎèô Ï§ë ÏóêÎü¨ Î∞úÏÉù: {e}")
        finally: 
            # ‚òÖ ÏûêÏõê Ìï¥Ï†ú ÏïàÏ†ÑÏû•Ïπò (Ï†ïÏùò Ïó¨Î∂Ä ÌôïÏù∏ ÌõÑ Îã´Í∏∞)
            if final_video: 
                try: final_video.close()
                except: pass
            for c in final_clips: 
                try: c.close()
                except: pass
            if conn and conn.is_connected(): 
                conn.close()
            
            # ÏûÑÏãú ÌååÏùº ÏÇ≠Ï†ú
            for f in all_temps:
                if f and os.path.exists(f):
                    try: os.remove(f)
                    except: pass
        
        time.sleep(10)
>>>>>>> a946f6f6b18974710cc396ee87547a607e4cf163

if __name__ == "__main__":
    run_engine()