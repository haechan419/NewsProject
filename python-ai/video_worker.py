import os
import time
import json
import re
import mysql.connector
from moviepy.config import change_settings 
from moviepy.editor import *
from moviepy.audio.AudioClip import AudioClip 
from moviepy.audio.fx.all import audio_fadein, audio_fadeout
import media_tools 
import openai

# [1. ê²½ë¡œ ë° í™˜ê²½ ì„¤ì •]
# ì´ë¯¸ì§€ë§¤ì§ ê²½ë¡œ (ì‚¬ìš©ìë‹˜ í™˜ê²½ ìœ ì§€)
IMAGEMAGICK_BINARY = r"D:\ImageMagick-7.1.2-Q16-HDRI\magick.exe"
change_settings({"IMAGEMAGICK_BINARY": IMAGEMAGICK_BINARY})


# íŒ€ í”„ë¡œì íŠ¸ DB ì„¤ì • (newsdbë¡œ í†µí•©)
DB_CONFIG = {
    'host': 'localhost', 
    'user': 'root', 
    'password': '1234', 
    'database': 'newsdb' # ë°ì´í„°ë² ì´ìŠ¤ëª… ìˆ˜ì • ì™„ë£Œ
}

# ì˜ìƒ ê²°ê³¼ë¬¼ì´ ì €ì¥ë  ë°±ì—”ë“œ ê²½ë¡œ (Spring Boot upload í´ë”)
# êµ¬ì¡°: NEWSPROJECT-MASTER/fullStc/upload/videos
OUTPUT_DIR = r"D:\NewsProject-master\NewsProject-master\fullStc\upload\videos"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ------------------------------------------------------------------------------
# [2. AI Director: ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±]
# ------------------------------------------------------------------------------
def get_storyboard_from_ai(news_text):
    print("ğŸ¤– [AI Director] ë‰´ìŠ¤ ìš”ì•½ë³¸ ê¸°ë°˜ ì˜ìƒ êµ¬ì„± ì¤‘...")
    system_prompt = """
    ë„ˆëŠ” ì „ë¬¸ ë‰´ìŠ¤ ì˜ìƒ í¸ì§‘ìì•¼. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê±°ì³ 30ì´ˆ ì´ë‚´ì˜ ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§œì¤˜.

    1. [ì „ì²´ ë§¥ë½ íŒŒì•…]: ì…ë ¥ëœ ê¸°ì‚¬ ì „ì²´ì˜ í•µì‹¬ ì£¼ì œë¥¼ ë¨¼ì € íŒŒì•…í•´.
    2. [ì¥ë©´ êµ¬ì„±]: ê¸°ì‚¬ë¥¼ ì„œë¡ -ë³¸ë¡ -ê²°ë¡  3ì¥ë©´ìœ¼ë¡œ ìš”ì•½í•´.
    3. [í‚¤ì›Œë“œ ì„ ì–¸]: ê° ë¬¸ì¥ì˜ í‚¤ì›Œë“œëŠ” 'ì „ì²´ ì£¼ì œ'ì™€ 'í•´ë‹¹ ë¬¸ì¥'ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ ê³ ë ¤í•´ ì‘ì„±í•´.
       - ë°˜ë“œì‹œ **êµ¬ì²´ì ì¸ ì‹œê°ì  ë¬˜ì‚¬ê°€ ë‹´ê¸´ ì˜ì–´(English)**ë¡œ ì‘ì„±í•  ê²ƒ.
       - ì˜ˆ: ì „ì²´ ì£¼ì œê°€ 'ì‚¼ì„± ë°˜ë„ì²´'ë¼ë©´, 'í˜ì‹ 'ì´ë¼ëŠ” ë¬¸ì¥ì˜ í‚¤ì›Œë“œëŠ” 'Innovation'ì´ ì•„ë‹ˆë¼ 
         'Advanced microchip glowing circuit board'ì™€ ê°™ì´ í•´ë‹¹ ë§¥ë½ì˜ ì‚¬ë¬¼ë¡œ ì§€ì •í•´.
    4. [ì‹œê°„ ì œí•œ]: ì „ì²´ ë¶„ëŸ‰ì€ 25~30ì´ˆ ì‚¬ì´, ì´ ê¸€ì ìˆ˜ëŠ” 150ì ì´ë‚´ë¡œ ì œí•œí•´.

    ì¶œë ¥ í˜•ì‹: ì˜¤ì§ JSON [ {"text": "...", "keyword": "...", "type": "video"} ]
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": news_text}]
        )
        content = response.choices[0].message.content.strip()
        content = content.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\[.*\]', content, re.DOTALL)
        return json.loads(match.group()) if match else None
    except Exception as e:
        print(f"âš ï¸ AI ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

# ------------------------------------------------------------------------------
# [3. ì¥ë©´ ì œì‘ ë¡œì§ (ì‚¬ìš©ì ì›ë³¸ ìœ ì§€)]
# ------------------------------------------------------------------------------
def split_text_natural(text, min_len=8, max_len=18):
    words = text.split(' ')
    chunks, current_chunk, current_len = [], [], 0
    markers = ["ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì„œ", "ë¡œ", "ê³ ", "ë©°", "ìš”", "ì£ ", "ë‹¤"]
    for word in words:
        current_chunk.append(word); current_len += len(word) + 1
        if current_len >= max_len or (current_len >= min_len and any(word.endswith(m) for m in markers)):
            chunks.append(' '.join(current_chunk)); current_chunk, current_len = [], 0
    if current_chunk: chunks.append(' '.join(current_chunk))
    return chunks

def get_compatible_silence(duration, reference_clip):
    fps, nchannels = reference_clip.fps, reference_clip.nchannels
    make_frame = lambda t: [0]*nchannels if nchannels > 1 else 0
    return AudioClip(make_frame, duration=duration, fps=fps)

def make_scene_clip(text, keyword, media_type, index, video_mode="16:9"):
    is_portrait = (video_mode == "9:16")
    target_w, target_h = (720, 1280) if is_portrait else (1280, 720)
    font_scale = 0.065 if is_portrait else 0.045
    subtitle_max_len = 16 if is_portrait else 25
    
    audio_path = os.path.abspath(f"temp_audio_{index}.mp3")
    media_path_base = os.path.abspath(f"temp_media_{index}")
    temp_files = [audio_path]
    
    media_tools.create_tts(text, audio_path)
    time.sleep(1.0)
    tts_clip = AudioFileClip(audio_path)
    
    # ì˜¤ë””ì˜¤ íŒ¨ë”©
    p_start = get_compatible_silence(0.1, tts_clip)
    p_end = get_compatible_silence(0.5, tts_clip)
    tts_clip = tts_clip.fx(audio_fadein, 0.05).fx(audio_fadeout, 0.1)
    final_audio = concatenate_audioclips([p_start, tts_clip, p_end])
    duration = final_audio.duration

    # ë¹„ì£¼ì–¼ ì†ŒìŠ¤ í™•ë³´
    visual_clip = None
    media_path_img = media_path_base + ".jpg"
    media_path_vid = media_path_base + ".mp4"

    if media_type == 'image':
        if media_tools.generate_free_image(keyword, media_path_img, is_portrait):
            visual_clip = ImageClip(media_path_img).set_duration(duration)
            temp_files.append(media_path_img)

    if visual_clip is None: # ë¹„ë””ì˜¤ ì‹œë„
        if media_tools.download_pexels_video(keyword, media_path_vid, is_portrait):
            visual_clip = VideoFileClip(media_path_vid)
            temp_files.append(media_path_vid)
        else:
            visual_clip = ColorClip(size=(target_w, target_h), color=(30, 30, 30)).set_duration(duration)

    visual_clip = visual_clip.resize(newsize=(target_w, target_h))
    if hasattr(visual_clip, 'duration'):
        visual_clip = vfx.loop(visual_clip, duration=duration) if visual_clip.duration < duration else visual_clip.subclip(0, duration)
    
    visual_clip = visual_clip.set_audio(final_audio)

    # ìë§‰ ìƒì„±
    text_chunks = split_text_natural(text, min_len=8, max_len=subtitle_max_len)
    active_duration = tts_clip.duration
    start_time = 0.1
    sub_clips = []
    
    for chunk in text_chunks:
        c_duration = (len(chunk)/len(text)) * active_duration
        txt = TextClip(chunk, fontsize=int(target_w*font_scale), color='white', font="C:/Windows/Fonts/malgun.ttf", 
                       method='caption', align='center', size=(int(target_w*0.9), None))
        bg = ColorClip(size=(target_w, txt.h + 50), color=(0,0,0)).set_opacity(0.6)
        block = CompositeVideoClip([bg, txt.set_position('center')], size=bg.size).set_position(('center', 'bottom')).set_start(start_time).set_duration(c_duration)
        sub_clips.append(block)
        start_time += c_duration

    return CompositeVideoClip([visual_clip] + sub_clips), temp_files

# ------------------------------------------------------------------------------
# [4. ë©”ì¸ ë£¨í”„: DB ì—°ë™ ë° ì‘ì—… ì²˜ë¦¬]
# ------------------------------------------------------------------------------
def run_engine():
    print("ğŸš€ [Engine] ë‰´ìŠ¤ ì˜ìƒ ì œì‘ ì¼ê¾¼ì´ ì¶œê·¼í–ˆìŠµë‹ˆë‹¤! (newsdb ê°ì‹œ ì¤‘)")
    while True:
        conn = None
        try:
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor(dictionary=True)
            
            # PENDING ìƒíƒœì¸ ì‘ì—… 1ê°œ ê°€ì ¸ì˜¤ê¸°
            cursor.execute("""
    SELECT * FROM tbl_video_task 
    WHERE status = 'PENDING' 
    AND reg_date > NOW() - INTERVAL 15 MINUTE
    ORDER BY vno ASC LIMIT 1
""")
            task = cursor.fetchone()

            if task:
                vno = task['vno']
                print(f"ğŸ¬ [Job {vno}] ì œì‘ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ìœ í˜•: {task['task_type']})")
                
                cursor.execute("UPDATE tbl_video_task SET status = 'PROCESSING' WHERE vno = %s", (vno,))
                conn.commit()

                # ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±
                story_board = get_storyboard_from_ai(task['raw_text'])
                if not story_board:
                    story_board = [{"text": "ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.", "keyword": "digital news", "type": "video"}]

                final_clips, all_temps = [], []
                for i, scene in enumerate(story_board):
                    # video_mode ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê¸°ë³¸ê°’ "16:9" ì‚¬ìš©
                    v_mode = task.get('video_mode', '16:9')
                    clip, files = make_scene_clip(scene.get('text', ''), scene.get('keyword', 'news'), scene.get('type', 'video'), i, v_mode)
                    final_clips.append(clip)
                    all_temps.extend(files)

                # ê²°ê³¼ë¬¼ íŒŒì¼ëª… ë° ì €ì¥ ê²½ë¡œ ì„¤ì •
                file_name = f"result_vno_{vno}.mp4"
                save_path = os.path.join(OUTPUT_DIR, file_name)

                final_video = concatenate_videoclips(final_clips, method="compose")
                final_video.write_videofile(save_path, fps=24, codec='libx264', audio_codec='libmp3lame', threads=4)
                
                # ìì› í•´ì œ (WinError 32 ë°©ì§€)
                final_video.close()
                for c in final_clips: c.close()
                time.sleep(2)

                # DB ì—…ë°ì´íŠ¸ (ì™„ë£Œ ìƒíƒœ ë° ì˜ìƒ URL ì €ì¥)
                cursor.execute("UPDATE tbl_video_task SET status = 'COMPLETED', video_url=%s WHERE vno = %s", (file_name, vno))
                conn.commit()
                print(f"âœ… [Job {vno}] ì œì‘ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {save_path}")
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                for f in all_temps:
                    if f and os.path.exists(f):
                        try: os.remove(f)
                        except: pass
            
            cursor.close()
        except Exception as e:
            print(f"âŒ [Error] ì—”ì§„ ì‘ë™ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        finally: 
            if conn: conn.close()
        
        time.sleep(10) # 10ì´ˆë§ˆë‹¤ DB í™•ì¸

if __name__ == "__main__":
    run_engine()