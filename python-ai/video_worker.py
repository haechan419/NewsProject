import os, time, json, re, mysql.connector
from moviepy.config import change_settings 
from moviepy.editor import *
import media_tools 
import openai

# [1. í™˜ê²½ ì„¤ì •]
IMAGEMAGICK_BINARY = r"D:\ImageMagick-7.1.2-Q16-HDRI\magick.exe"
change_settings({"IMAGEMAGICK_BINARY": IMAGEMAGICK_BINARY})
DB_CONFIG = {'host': 'localhost', 'user': 'root', 'password': '1234', 'database': 'newsdb'}
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(BASE_DIR, "videos")

# [2. AI ìŠ¤í† ë¦¬ë³´ë“œ - ë¬¸ë§¥ ì¤‘ì‹¬ ê³ í€„ë¦¬í‹° ë¦¬í¬íŠ¸]
def get_storyboard_from_ai(news_text):
    print("ğŸ¤– [AI Director] ë¬¸ë§¥ ì¤‘ì‹¬ ê³ í€„ë¦¬í‹° ëŒ€ë³¸ êµ¬ì„± ì¤‘...")
    system_prompt = """
    ë„ˆëŠ” ì‹œì²­ë¥  1ìœ„ ë‰´ìŠ¤ì˜ ìˆ˜ì„ ì‘ê°€ì•¼. ë”±ë”±í•œ ì •ë³´ë¥¼ ì‹œì²­ìê°€ í¸í•˜ê²Œ ë“¤ì„ ìˆ˜ ìˆëŠ” 'ìŠ¤í† ë¦¬í…”ë§í˜• ë‰´ìŠ¤'ë¡œ ì¬êµ¬ì„±í•´ì¤˜.
    [ì‘ì„± ê·œì¹™]
    1. ë§¥ë½ ì „í™˜: 'í•œí¸', 'ì´ì–´ì„œ' ëŒ€ì‹  "IT ì†Œì‹ì— ì´ì–´ ì´ë²ˆì—” ê²½ì œ ë™í–¥ ì§šì–´ë´…ë‹ˆë‹¤"ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´.
    2. ì „ë¬¸ ì–´ë¯¸: "~ì¸ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡ŒìŠµë‹ˆë‹¤", "~í•  ì „ë§ì…ë‹ˆë‹¤" ì‚¬ìš©.
    3. ìë§‰ ìµœì í™”: ìë§‰ 1ì¤„ ë¶„ëŸ‰ì¸ ê³µë°± í¬í•¨ 30~35ì ë‚´ì™¸ê°€ ê°€ì¥ ì¢‹ì•„.
    4. ì‹œê°í™”: íŠ¹ì • ì¸ë¬¼/ê¸°ì—…ì€ 'image', ì¼ë°˜ ë°°ê²½ì€ 'video'ë¡œ ì§€ì •í•´.
    í˜•ì‹: JSON [ {"text": "ìì—°ìŠ¤ëŸ¬ìš´ ë©˜íŠ¸", "keyword": "ì˜ì–´ í‚¤ì›Œë“œ", "type": "video|image"} ]
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ê¸°ì‚¬ë“¤ì„ ì—®ì–´ì¤˜: {news_text}"}
            ],
            temperature=0.8
        )
        content = response.choices[0].message.content.strip()
        match = re.search(r'\[.*\]', content.replace("```json", "").replace("```", ""), re.DOTALL)
        return json.loads(match.group()) if match else None
    except Exception as e:
        print(f"âš ï¸ ëŒ€ë³¸ ìƒì„± ì˜¤ë¥˜: {e}"); return None

# [2.5 í•œêµ­í˜• ìƒì§•ë¬¼ & ì§€ì—­ ìµœì í™” í•„í„°]
def apply_korean_context_filter(keyword):
    """AIê°€ ìƒì„±í•œ ì˜ì–´ í‚¤ì›Œë“œë¥¼ í•œêµ­ì  ìƒì§•ë¬¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤."""
    k = keyword.lower()
    
    # 1. ì •ì¹˜ ë° ì¸ë¬¼ ìƒì§•í™” (ì¸ë¬¼ ì‹¤ëª… ëŒ€ì‹  ìƒì§•ë¬¼ë¡œ)
    politics_map = {
        "politician": "The National Assembly of the Republic of Korea, Yeouido",
        "assembly": "The National Assembly of the Republic of Korea building",
        "prosecutor": "Supreme Prosecutors Office of the Republic of Korea building, Seoul",
        "investigation": "Press conference with many microphones and camera flashes, professional news",
        "court": "The Supreme Court of Korea gavel and scales of justice",
        "president": "The Office of the President of the Republic of Korea, Yongsan",
    }
    
    # 2. í•œêµ­ ë„ì‹œë³„ ëŒ€í‘œ ëœë“œë§ˆí¬ (í•´ì™¸ ë„ì‹œ ë°©ì§€)
    city_map = {
        "seoul": "N Seoul Tower and Han River cityscape",
        "incheon": "Incheon Bridge South Korea",
        "busan": "Gwangandaegyo Bridge Busan",
        "daegu": "83 Tower night view Daegu"
    }

    # í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¥ ë¨¼ì € ë°œê²¬ë˜ëŠ” ìƒì§•ë¬¼ ì ìš©)
    for key, val in politics_map.items():
        if key in k: return val
    for key, val in city_map.items():
        if key in k: return val
        
    # ê¸°ë³¸: í•œêµ­ì  ë§¥ë½ ê°•ì œ ë¶€ì—¬
    return f"{keyword}, South Korea style"

# [3. ì¥ë©´ ì œì‘ - ê³ ì • ìë§‰ ë° ë¶„í•  ë¡œì§ í•µì‹¬]
def make_hybrid_scene(scene, index, video_mode="16:9"):
    is_portrait = (video_mode == "9:16")
    target_w, target_h = (720, 1280) if is_portrait else (1280, 720)
    audio_path = os.path.join(BASE_DIR, f"temp_audio_{index}.mp3")
    media_path = os.path.join(BASE_DIR, f"temp_media_{index}")
    filtered_k = apply_korean_context_filter(scene.get('keyword', 'news'))
    print(f"ğŸ” [Filter] '{scene['keyword']}' -> '{filtered_k}'")
    
    # 1. TTS ë° ì˜¤ë””ì˜¤
    if not media_tools.create_tts(scene['text'], audio_path): return None, []
    tts_clip = AudioFileClip(audio_path)
    duration = tts_clip.duration 
    temp_files = [audio_path]

    # 2. ë¹„ì£¼ì–¼ ë¡œì§ (ì´ì „ê³¼ ë™ì¼)
    visual_clip = None
    if scene['type'] == 'image':
        img_file = media_path + ".jpg"
        if media_tools.generate_free_image(filtered_k, img_file, is_portrait):
            visual_clip = ImageClip(img_file).set_duration(duration + 0.5)
            temp_files.append(img_file)

    if visual_clip is None:
        vid_file = media_path + ".mp4"
        if media_tools.download_pexels_video(scene['keyword'], vid_file, is_portrait):
            raw = VideoFileClip(vid_file)
            visual_clip = vfx.loop(raw, duration=duration + 1) if raw.duration < duration else raw
            temp_files.append(vid_file)
        else: 
            img_file = media_path + "_fallback.jpg"
            if media_tools.generate_free_image(scene['keyword'], img_file, is_portrait):
                visual_clip = ImageClip(img_file).set_duration(duration + 0.5)
                temp_files.append(img_file)
            else:
                visual_clip = ColorClip(size=(target_w, target_h), color=(30, 30, 30)).set_duration(duration)

    visual_clip = visual_clip.resize(newsize=(target_w, target_h)).subclip(0, duration)

    # 3. ìë§‰ ë¡œì§ (â˜… ì•ˆì „ì¥ì¹˜ ì¶”ê°€ë¨ â˜…)
    fixed_fs = 35 if is_portrait else 50 
    pos_y = target_h * (0.80 if is_portrait else 0.85)
    # í™”ë©´ ë„ˆë¹„ì˜ 90%ë¥¼ ë„˜ì§€ ëª»í•˜ë„ë¡ ì œí•œì„  ì„¤ì •
    max_txt_w = target_w * 0.90 
    
    full_text = scene['text']
    subtitle_clips = []

    # ë„ìš°ë¯¸ í•¨ìˆ˜: í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± ë° ì•ˆì „ ë¦¬ì‚¬ì´ì§•
    def create_safe_text_clip(txt_content, duration_part, start_time=0):
        # ì¼ë‹¨ ê³ ì • í¬ê¸°ë¡œ ìƒì„±
        st = TextClip(txt_content, fontsize=fixed_fs, color='white', font="C:/Windows/Fonts/malgunbd.ttf", method='label')
        # â˜… í•µì‹¬: í™”ë©´ë³´ë‹¤ ë„“ìœ¼ë©´ ê°•ì œë¡œ ì¤„ì„ (ì•ˆì „ì¥ì¹˜)
        if st.w > max_txt_w:
            st = st.resize(width=max_txt_w)
        return st.set_duration(duration_part).set_start(start_time).set_position('center')

    # ë¶„í•  ë¡œì§ ì ìš©
    if len(full_text) > 30:
        mid = len(full_text) // 2
        split_idx = full_text.find(' ', mid - 5, mid + 5)
        if split_idx == -1: split_idx = mid
        parts = [full_text[:split_idx], full_text[split_idx:].strip()]
        part_dur = duration / 2
        for i, p in enumerate(parts):
            # ë„ìš°ë¯¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì•ˆì „í•˜ê²Œ ìƒì„±
            st = create_safe_text_clip(p, part_dur, i * part_dur)
            subtitle_clips.append(st)
    else:
        # ë„ìš°ë¯¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì•ˆì „í•˜ê²Œ ìƒì„±
        st = create_safe_text_clip(full_text, duration)
        subtitle_clips.append(st)

    # ìë§‰ ë°°ê²½ë°” (ë†’ì´ ê³ ì •)
    bg_h = fixed_fs + 40
    txt_bg = ColorClip(size=(target_w, bg_h), color=(0,0,0)).set_opacity(0.6).set_duration(duration)
    
    subtitle_group = CompositeVideoClip([txt_bg] + subtitle_clips, size=(target_w, bg_h)).set_position(('center', pos_y))

    # 4. ìµœì¢… í•©ì„±
    final_scene = CompositeVideoClip([visual_clip, subtitle_group]).set_audio(tts_clip)
    return final_scene, temp_files


# [4. ë©”ì¸ ì—”ì§„ ë£¨í”„]
def run_engine():
    print("ğŸš€ [Engine] ì•„ë‚˜ìš´ì„œ ì‹±í¬ & ìë§‰ ë¶„í•  ëª¨ë“œ ê°€ë™!")
    while True:
        conn = None
        all_temps, final_clips = [], []
        final_video = None
        try:
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor(dictionary=True)
            cursor.execute("SELECT * FROM tbl_video_task WHERE status = 'PENDING' ORDER BY vno ASC LIMIT 1")
            task = cursor.fetchone()

            if task:
                vno = task['vno']
                print(f"ğŸ¬ [Job {vno}] ì œì‘ ì‹œì‘...")
                cursor.execute("UPDATE tbl_video_task SET status = 'PROCESSING' WHERE vno = %s", (vno,))
                conn.commit()

                story_board = get_storyboard_from_ai(task['raw_text'])
                if story_board:
                    for i, scene in enumerate(story_board):
                        clip, files = make_hybrid_scene(scene, i, task.get('video_mode', '16:9'))
                        if clip:
                            final_clips.append(clip)
                            all_temps.extend(files)

                    if final_clips:
                        file_name = f"result_vno_{vno}.mp4"
                        save_path = os.path.join(OUTPUT_DIR, file_name)
                        final_video = concatenate_videoclips(final_clips, method="compose")
                        final_video.write_videofile(save_path, fps=24, codec='libx264', audio_codec='aac', threads=8, preset='ultrafast')
                        cursor.execute("UPDATE tbl_video_task SET status = 'COMPLETED', video_url=%s WHERE vno = %s", (file_name, vno))
                        conn.commit()
                        print(f"âœ… [Job {vno}] ì œì‘ ì™„ë£Œ!")
            cursor.close()
        except Exception as e: print(f"âŒ ì—ëŸ¬: {e}")
        finally: 
            if conn and conn.is_connected(): conn.close()
            if final_video: final_video.close()
            for c in final_clips: c.close()
            for f in all_temps:
                if f and os.path.exists(f):
                    try: os.remove(f)
                    except: pass
        time.sleep(10)

if __name__ == "__main__":
    run_engine()